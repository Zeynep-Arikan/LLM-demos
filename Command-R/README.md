## ğŸ“š Project Description
In this project, I took a text file (example content from Wikipedia), split it into small chunks, and converted these chunks into vector representations using Cohere's embed-english-v2.0 embedding model.
The resulting vectors were stored in a Chroma vector database, and I built a retriever that can return the most relevant text chunks for a given user question.

## ğŸ¤– Language Model (LLM)
For the question-answering process, I used Cohereâ€™s command-r language model.
This model not only generates high-quality responses but also includes a built-in hallucination grader, which helps reduce the risk of incorrect or made-up answers.

<pre>llm = ChatCohere(model="command-r", temperature=0)</pre>

## ğŸ§  Embedding Model
To transform the text into vector form, I used Cohereâ€™s embed-english-v2.0 embedding model.

<pre>embd = CohereEmbeddings(model="embed-english-v2.0")</pre>


## ğŸ“˜ TÃ¼rkÃ§e aÃ§Ä±klama
Bu projede bir metin dosyasÄ±nÄ± (Ã¶rnek olarak Wikipedia'dan alÄ±nmÄ±ÅŸ iÃ§erik) kÃ¼Ã§Ã¼k parÃ§alara bÃ¶lÃ¼p, bu parÃ§alarÄ± Cohereâ€™Ä±n embed-english-v2.0 embedding modeli ile vektÃ¶rlere dÃ¶nÃ¼ÅŸtÃ¼rÃ¼ldÃ¼.
Bu vektÃ¶rleri Chroma veri tabanÄ±na kaydettim ve bir retriever oluÅŸturarak, kullanÄ±cÄ± sorularÄ±na en uygun iÃ§erik parÃ§alarÄ±nÄ± bulabilen bir yapÄ± kuruldu.
Soru-cevap iÅŸlemlerinde Cohereâ€™Ä±n command-r dil modeli kullanÄ±ldÄ±.
Bu model, geliÅŸmiÅŸ cevaplar Ã¼retmenin yanÄ± sÄ±ra, halÃ¼sinasyon kontrolÃ¼ yapan yerleÅŸik bir "grader" da iÃ§erir. Bu sayede modelin uydurma cevap verme olasÄ±lÄ±ÄŸÄ± azaltÄ±lmÄ±ÅŸ olur.
Metni sayÄ±sal vektÃ¶rlere dÃ¶nÃ¼ÅŸtÃ¼rmek iÃ§in Cohereâ€™Ä±n embed-english-v2.0 modeli kullanÄ±ldÄ±.
